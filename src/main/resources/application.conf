# Global settings
global {
  #in test mode the input dataset is limited to only part of the entries
  testMode = false
  #weather to include all the issue comments or only its full description
  includeComments = true
  # type of tokenizer to use 0 - dummy | 1 - regexp | 2 - NLP | 3 - POS
  tokenizerType = 3
  # mimimum token length
  minWordSize = 4
  # time intervals to consider
  timeIntervals = 3
  # mimimum number of issues fixed in a time interval in
  # order to consider the user a valid candidate
  issuesThreshold = 3
  # time interval in days in which to apply the issuesThreshold
  timeThreshold = 30

}

# Execution phases
phases {
  cleansing = false
  transform = false
  training = true
  testing = true
  pca = false
  undersampling = false
}

# trainig specific params
training {
  normalize = false
  includeCategory = true
  categoryScalingFactor = 92.5
}

# Spark context
spark {
  master = "local"
  appName = "Columb(ug)us"
  driver.memory = 8g
  client.memory = 8g
}

# MySQL server
mySQL {
  url = "jdbc:mysql://localhost:3306/eclipsebugs"
  username = "root"
  password = "mysql"
}