reccsys {

  # Global settings
  global {
    #in test mode the input dataset is limited to only part of the entries
    testMode = false
    # type of tokenizer to use 0 - dummy | 1 - regexp | 2 - NLP | 3 - POS
    tokenizerType = 3
    # mimimum token length
    minWordSize = 4
    # time intervals to consider
    timeIntervals = 3
    # mimimum number of issues fixed in a time interval in
    # order to consider the user a valid candidate
    issuesThreshold = 3
    # time interval in days in which to apply the issuesThreshold
    timeThreshold = 30
    # use issues updated no later than thin number of days back
    timeThresholdForTraining = 240
    # field id used for bug status (11 for eclipse, 12 for netbeans, 30 for firefox)
    # statusFieldId = 12
    # true to use assign_to field, false to identify the user based on who marked the bug as fixed
    use_assigned_to = false
  }

  filesystem {
    # Liunx
    # root: "/home/aflorea/data/columbugus/firefox"
    # root: "/home/aflorea/data/columbugus/netbeans_simple_lda_graph_1"
    # root: "/home/aflorea/data/columbugus/eclipse"
    # root: "/home/aflorea/data/columbugus/netbeans_final_norm"
    # Mac
    # root: "/Users/acflorea/phd/columbugus_data/netbeans_simple_lda_graph_1"
    # root: "/Users/acflorea/phd/columbugus_data/eclipse_simple_lda_graph_1"
    # root: "/Users/acflorea/phd/columbugus_data/eclipse_final_norm"
    # root: "/Users/acflorea/phd/columbugus_data/firefox_final"
    # root: "/Users/acflorea/phd/columbugus_data/eclipse_final"
    # root: "/Users/acflorea/phd/columbugus_data/netbeans_final_2"
    # root: "/Users/acflorea/phd/columbugus_data/firefoxnew_simple_lda_graph_1"

    # GCloud
    # root: "gs://dataproc-1e7dadea-6c68-4715-b356-2a8742d25022-eu/columbugus"
  }

  # MySQL server
  mySQL {
    #url = "jdbc:mysql://localhost:3306/firefoxbugs"
    #url = "jdbc:mysql://localhost:3306/firefoxbugs_new"
    #url = "jdbc:mysql://localhost:3306/netbeansbugs"
    #url = "jdbc:mysql://localhost:3306/eclipsebugs"
    username = "root"
    password = "mysql"
  }

  # Execution phases
  phases {
    cleansing = true
    transform = true
    preprocess = true
  }

  # transform specific params
  transform {
    minDocFreq = 2
    maxDocFreq = 1000 # ~15% of the training data size
    smoothTF = false
    timeDecay = false
  }

  # preprocess specific params
  preprocess {
    removeOutliers = true

    simple = true

    pca = false

    chi2 = true
    chi2Features = 1000

    lda = true
    ldaTopics = "1, 5, 10, 25, 50, 100, 200, 300, 400, 500, 750, 1000, 1250, 1500"
    ldaOptimizer = "em"
    # topic concentration - 0.1 + 1 (em); 1.0 / k (online) #1.1
    ldaAlpha = -1
    # document concentration - 50/k +1 # 1.05
    ldaBeta = -1

    modelsNo = 1
    trainingSteps = 100
    undersampling = false

    minMaxScaling = false
    normalize = false

    useCategorical = true

    includeCategory = true
    categoryScalingFactor = "1, 5, 10, 25, 50, 75, 100, 125, 150"
    # categoryMultiplier = "1"

    includeProduct = true
    productScalingFactor = "1, 5, 10, 25, 50, 75, 100, 125, 150"
    # productScalingFactor = "5"
    # productMultiplier = "1"

  }

  postprocess {
    normalize = false
    removeOutliers = false
  }

  # Spark context
  spark {
    //master = "local-cluster[3, 1, 2048]"
    master = "local"
    appName = "Columb(ug)us"
    driver.memory = 8G
    client.memory = 2G
    driver.maxResultSize = 2048
    replicationFactor = 1
    maxClassToTrain = -1
  }


  # Slick - db to populate
  mySQLBugsDB = {
    url = "jdbc:mysql://localhost:3306/firefoxbugs?characterEncoding=UTF-8"
    slick.driver = scala.slick.driver.MySQLDriver
    driver = com.mysql.jdbc.Driver
    connectionPool = disabled
    keepAliveConnection = true
    user = "root"
    password = "mysql"
    autoCommit = true
  }

}